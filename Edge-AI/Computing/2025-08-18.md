# 📚 阅读日志 | 2025-08-19  
> 今日目标：10 篇 | 实际完成：1 / 10  

---

## ① PipeDream: Fast and Efficient Pipeline Parallel DNN Training  
- **作者**: Aaron Harlap, Deepak Narayanan, Amar Phanishayee, Vivek Seshadri, Nikhil Devanur, Greg Ganger, Phil Gibbons  
- **阅读时间**: 60 min  
- **标签**: #深度学习 #分布式训练 #管道并行 #GPU

> **TL;DR**  
> PipeDream 是一种针对 GPU 的分布式深度神经网络（DNN）训练系统，通过管道并行（pipeline parallelism）大幅减少了数据并行训练中的通信开销，同时优化了计算资源的利用。实验表明，PipeDream 在多种 DNN 模型上比数据并行训练快 5 倍，尤其在通信瓶颈明显的场景下表现出色。

---

### 核心痛点  
| 问题 | 原因 | 传统方案缺陷 |
|---|---|---|
| **通信开销大** | 数据并行训练中，模型参数同步需要大量通信 | 随着模型增大和 GPU 计算能力提升，通信瓶颈愈发明显 |
| **计算资源利用率低** | 传统模型并行训练中，每次只有一个工作阶段活跃 | 导致 GPU 大量时间闲置，无法充分利用计算资源 |
| **难以平衡负载** | 不同 DNN 层的计算量差异大 | 传统方法难以自动划分模型以平衡负载 |

---

### 解决方案 (PipeDream)  
#### 1️⃣ 管道并行设计  
- **管道并行**：将 DNN 分成多个阶段，每个阶段分配给不同的 GPU，通过管道化处理多个小批量数据，确保所有 GPU 始终忙碌。
- **数据并行结合**：在某些阶段使用数据并行，平衡计算负载，进一步优化性能。

#### 2️⃃ 关键技术  
| 技术 | 作用 | 关键思想 |
|---|---|---|
| **自动分区** | 自动划分 DNN 层到不同 GPU | 使用动态规划算法，平衡计算负载并最小化通信 |
| **权重版本管理** | 确保前向和反向传播使用一致的权重 | 通过权重存储（weight stashing）和垂直同步（vertical sync）技术 |
| **工作调度** | 优化前向和反向传播的调度 | 采用 1F1B（一前一后）调度策略，避免 GPU 空闲 |

---

### 性能结果  
| 模型 | 数据集 | 机器数 | 数据并行速度提升 | PipeDream 配置 | PipeDream 速度提升 | 通信减少 |
|---|---|---|---|---|---|---|
| VGG16 | ILSVRC12 | 8 | 2.35× | 7-1 | 7.04× | 95% |
| Inception-v3 | ILSVRC12 | 8 | 7.66× | 8 | 7.66× | 0% |
| S2VT | MSVD | 4 | 1.10× | 2-1-1 | 3.34× | 95% |

---

### 一句话总结  
PipeDream 通过结合管道并行、模型并行和数据并行，大幅减少了通信开销，优化了 GPU 资源利用，显著提升了分布式 DNN 训练的效率，尤其在通信瓶颈明显的场景下表现出色。

文章《PipeDream: Fast and Efficient Pipeline Parallel DNN Training》的实验设计如下：

1. **实验目标**：验证PipeDream系统在减少通信开销、提高训练效率方面相对于数据并行（BSP）方法的优势。

2. **实验设置**：
   - 使用两个不同的集群（Cluster-A和Cluster-B），分别配备NVIDIA Titan X和V100 GPU，以及不同带宽的网络连接。
   - 选择五种不同的DNN模型：VGG16、Inception-v3、ResNet-50、AlexNet和S2VT，覆盖CNNs和RNNs（seq-to-seq）两类。
   - 使用两个数据集：ILSVRC12（用于训练VGG16和Inception-v3）和MSVD（用于训练S2VT模型）。

3. **训练方法**：
   - 对比了单机器训练、数据并行（BSP）训练以及PipeDream训练。
   - 调整学习率以加速模型收敛到目标准确率。

4. **评估指标**：
   - 训练时间：直到模型达到预定的验证准确率（例如，VGG16的68% top-1准确率）。
   - 通信开销：比较不同训练方法之间的通信量。
   - 准确率：模型在验证集上的性能。

5. **实验结果**：
   - PipeDream在多个模型上实现了显著的速度提升，与数据并行（BSP）相比，最高可达5倍。
   - PipeDream显著减少了通信开销，最高可达95%。

6. **结论**：
   - PipeDream通过结合模型并行、管道并行和数据并行，有效地解决了大规模DNN训练中的通信瓶颈问题，提高了训练效率。

实验设计旨在全面评估PipeDream系统在不同硬件配置、不同模型和数据集上的性能，确保实验结果的可靠性和普适性。


## ① GPipe: Easy Scaling with Micro-Batch Pipeline Parallelism
- **作者**: Yanping Huang, Youlong Cheng, Ankur Bapna, Orhan Firat, HyoukJoong Lee, Mia Xu Chen, Jiquan Ngiam, Dehao Chen, Quoc V. Le, Yonghui Wu, Zhifeng Chen
- **阅读时间**: 60 min
- **标签**: #深度学习 #模型并行 #管道并行 #大规模神经网络

> **TL;DR**  
> GPipe 是一个灵活的库，通过微批次管道并行算法，实现了任意深度神经网络架构的高效扩展，支持在多个加速器上进行模型训练。实验表明，GPipe 在图像分类和多语言神经机器翻译任务上，能够显著提高大规模神经网络的训练效率和模型质量。

---

### 核心痛点  
| 问题 | 原因 | 传统方案缺陷 |
|---|---|---|
| **扩展性差** | 单个加速器的内存限制 | 需要特殊算法或基础设施 |
| **训练效率低** | 模型并行算法设计和实现困难 | 架构和任务特定，缺乏灵活性 |
| **硬件利用率低** | 通信开销大 | 需要高性能的设备互连 |

---

### 解决方案 (GPipe)  
#### 1️⃣ 管道并行设计  
- **微批次处理**：将小批量数据分成更小的微批次，通过不同的加速器进行流水线处理。
- **同步梯度更新**：在每个小批量结束时，累积所有微批次的梯度并更新模型参数。

#### 2️⃣ 关键技术  
| 技术 | 作用 | 关键思想 |
|---|---|---|
| **微批次分割** | 减少每个加速器的内存需求 | 通过分割小批量数据来平衡负载 |
| **重新计算** | 减少激活内存需求 | 在反向传播中重新计算前向函数 |
| **通信优化** | 降低通信开销 | 仅在分区边界传递激活张量 |

---

### 性能结果  
| 模型 | 数据集 | 参数数量 | 准确率 | 速度提升 |
|---|---|---|---|---|
| AmoebaNet | ImageNet-2012 | 557M | 84.4% top-1 | 显著 |
| Transformer | 多语言翻译 | 6B | 优于双语模型 | 显著 |

---

### 一句话总结  
GPipe 通过微批次管道并行和同步梯度更新，实现了大规模神经网络的高效扩展和训练，显著提高了图像分类和多语言翻译任务的性能。

### 实验设计

1. **目标**：展示GPipe库在不同网络架构和任务上扩展大型神经网络的能力。

2. **任务**：
   - 图像分类：训练一个5570万参数的AmoebaNet模型，并在ImageNet-2012数据集上达到84.4%的top-1准确率。
   - 多语言神经机器翻译：训练一个单一的60亿参数、128层的Transformer模型，该模型在超过100种语言的语料库上训练，并在所有双语模型上实现更好的质量。

3. **模型架构**：
   - 使用了两种不同类型的模型架构：AmoebaNet卷积模型和Transformer序列到序列模型。

4. **实验设置**：
   - 在Cloud TPUv2和v3上进行实验，这些TPU具有不同数量的内存。
   - 对于AmoebaNet，使用固定输入图像大小224×224和128的小批量大小。
   - 对于Transformer模型，使用固定的词汇量32k，序列长度1024和批量大小32。

5. **性能评估**：
   - 评估了GPipe在不同数量的分区和不同数量的微批次下的性能。
   - 报告了AmoebaNet-D (18,256)和Transformer-48使用GPipe在不同分区数量和微批次数量下的标准化训练吞吐量。

6. **通信开销**：
   - 在没有高速互连的多个NVIDIA P100 GPU上运行实验，以测量GPipe的通信开销。

7. **结果**：
   - GPipe能够支持比单个加速器可能的更大的模型大小，例如在8个加速器上将AmoebaNet扩展到18亿参数。
   - 对于Transformer模型，使用128个分区，GPipe允许将模型扩展到8390亿参数，比单个加速器上可能的模型大小增加了298倍。

8. **结论**：
   - GPipe通过微批次分割和同步梯度更新，实现了高效的模型并行训练，几乎线性地扩展了设备数量。

文章的实验部分详细评估了GPipe在不同硬件配置下的性能，包括内存利用率、训练效率和通信成本。实验结果表明，GPipe能够有效地扩展大型神经网络，并且在图像分类和多语言机器翻译任务上取得了显著的性能提升。


## ① Splitwise: Efficient Generative LLM Inference Using Phase Splitting
- **作者**: Pratyush Patel, Esha Choukse, Chaojie Zhang, Aashaka Shah, Iñigo Goiri, Saeed Maleki, Ricardo Bianchini
- **阅读时间**: 60 min
- **标签**: #深度学习 #大语言模型 #模型推理 #相位分割

> **TL;DR**  
> Splitwise 是一种模型部署和调度技术，它将大型语言模型（LLM）推理请求的两个阶段（计算密集型的提示计算阶段和内存密集型的令牌生成阶段）分割到不同的机器上。利用这一技术，设计了针对吞吐量、成本和功耗优化的同构和异构LLM推理集群，相比当前设计，Splitwise集群在降低20%成本的同时实现了高达1.4×的吞吐量提升。或者在相同功耗和成本下，可以提供2.35×更多的吞吐量。

---

### 核心痛点  
| 问题 | 原因 | 传统方案缺陷 |
|---|---|---|
| **计算资源浪费** | 令牌生成阶段不需要最新GPU的计算能力 | 相同硬件上运行两个阶段导致资源未充分利用 |
| **功耗和成本高** | 使用昂贵且耗电的GPU | 需要更经济的解决方案 |
| **硬件利用率不足** | 单个机器上运行整个推理请求 | 需要更高效的硬件资源管理 |

---

### 解决方案 (Splitwise)
#### 1️⃣ 分离部署
- **阶段分割**：将LLM推理分为计算密集型的提示计算阶段和内存密集型的令牌生成阶段，并在不同的机器上运行。

#### 2️⃣ 集群优化
| 优化目标 | 方法 | 关键思想 |
|---|---|---|
| **吞吐量** | 设计同构和异构集群 | 针对不同阶段使用适合的硬件 |
| **成本** | 优化硬件资源管理 | 降低GPU使用成本 |
| **功耗** | 降低功耗和成本 | 提高能源效率 |

---

### 性能结果  
| 指标 | Splitwise vs 现有设计 |
|---|---|
| **吞吐量提升** | 高达1.4× | 更高效的硬件利用 |
| **成本降低** | 降低20% | 更经济的GPU使用 |
| **功耗优化** | 2.35×吞吐量提升 | 在相同功耗和成本下 |

---

### 一句话总结  
Splitwise通过将大语言模型推理的两个阶段分割到不同机器上，实现了对硬件资源的高效管理，从而在降低成本和功耗的同时提升了推理吞吐量。

文章《Splitwise: Efficient Generative LLM Inference Using Phase Splitting》的实验设计如下：

### 实验目标
验证Splitwise方法在提高大型语言模型（LLM）推理效率方面的有效性。Splitwise通过将推理过程分为计算密集型的提示计算阶段和内存密集型的令牌生成阶段，并在不同的机器上并行这两个阶段来提高效率。

### 实验设置
- **硬件环境**：实验在具有不同硬件配置的集群上进行，包括NVIDIA A100和H100 GPU，以及通过InfiniBand连接的机器。
- **模型选择**：实验中使用了两种模型架构：AmoebaNet卷积模型和Transformer序列到序列模型。
- **数据集**：使用了来自Microsoft Azure的两个LLM推理服务的生产日志，包括编码和对话场景。

#### 实验方法
- **性能特征分析**：分析了LLM推理中提示计算和令牌生成阶段的执行和资源利用模式的差异。
- **Splitwise实现**：实现了Splitwise方法，包括KV-cache传输优化和两级调度策略。
- **集群设计探索**：使用Splitwise方法设计了针对吞吐量、成本和功耗优化的同构和异构LLM推理集群。
- **性能评估**：评估了使用Splitwise设计的系统在生产日志上的性能，包括吞吐量、成本和功耗。

### 实验结果
- **吞吐量提升**：Splitwise集群在降低20%成本的同时实现了高达1.4倍的吞吐量提升，或者在相同成本和功耗下实现了2.35倍的吞吐量提升。
- **效率优化**：通过Splitwise，实现了几乎线性的设备扩展速度，同时保持了硬件的高利用率和训练稳定性。

### 结论
实验结果表明，Splitwise方法能够有效地提高LLM推理的效率，特别是在处理大规模模型时。通过在不同硬件上分割计算和内存密集型任务，Splitwise能够在保持高性能的同时降低成本和功耗。

这篇文章的实验设计全面评估了Splitwise方法在不同硬件配置和模型架构上的性能，验证了其在提高LLM推理效率方面的有效性。
