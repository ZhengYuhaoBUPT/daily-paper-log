# 📅 2025-07-15 Paper Reading Log
> 今日目标：10 篇 | 实际完成：4 / 10  
Today’s Goal: 10 papers  
Focus: LLM

# 📚 Table of Contents

1. [1. Edge-Enhanced Intelligence: A Comprehensive Survey of Large Language Models and Edge-Cloud Computing Synergy](#1-edge-enhanced-intelligence-a-comprehensive-survey-of-large-language-models-and-edge-cloud-computing-synergy)  
2. [2. Mobile Edge Intelligence for Large Language Models: A Contemporary Survey](#2-mobile-edge-intelligence-for-large-language-models-a-contemporary-survey)  
3. [3. Large Language Model (LLM) for Telecommunications: A Comprehensive Survey on Principles, Key Techniques, and Opportunities](#3-large-language-model-llm-for-telecommunications-a-comprehensive-survey-on-principles-key-techniques-and-opportunities)  
4. [4. Large Language Model Based Multi-Objective Optimization for Integrated Sensing and Communications in UAV Networks](#4-large-language-model-based-multi-objective-optimization-for-integrated-sensing-and-communications-in-uav-networks)



# 1. Edge-Enhanced Intelligence: A Comprehensive Survey of Large Language Models and Edge-Cloud Computing Synergy
> 原文链接：<https://ieeexplore.ieee.org/document/11075838>  
> 作者：Xiuhua Li, Hui Li, Chuan Sun, Qilin Fan, Zhu Han, Victor C. M. Leung  
> 期刊：IEEE Communications Surveys & Tutorials  
> 标签：#边缘智能 #大型语言模型 #边缘云计算 #协同效应

---

## 摘要
> 大型语言模型 (LLM)（例如 ChatGPT、GPT-4 和 Sora）从根本上改变了我们的日常生活，催化了自然语言处理和计算机视觉领域的突破，并彻底改变了人机交互。然而，其变革潜力因所需的巨大计算资源而受到阻碍。为了应对这一挑战，LLM 与边缘云计算的融合已成为提升人工智能能力的焦点。本综述全面探索了边缘增强智能的前景，特别关注 LLM 与边缘云计算之间的协同作用。我们从数据、计算能力、模型训练和推理等方面深入探讨了 LLM 的演进、架构复杂性以及在边缘环境中部署它们所面临的计算挑战。此外，我们从两个关键方面探讨了边缘云计算与LLM之间的双向共生关系：边缘云计算赋能的LLM（Edge4LLMs）和LLM驱动的边缘云计算（LLMs4Edge）。之后，我们探讨了边缘云计算与LLM之间的动态协作，强调了它们在优化智能应用的效率、实时性和可扩展性方面的互补作用。通过对现有研究和实际应用的广泛回顾，本综述深入分析了边缘增强智能的现状，识别了关键挑战，并提出了未来研究和发展的潜在途径。本综述旨在全面了解LLM新兴的边缘增强智能范式，从而促进该领域的深入讨论并推动其发展。


## 引言
### 背景
人工通用智能（AGI）是科技领域长期追求的目标，代表能够像人类一样理解、学习和执行多种任务的智能系统。大型语言模型（LLMs），如ChatGPT和GPT-4，在自然语言处理、计算机视觉和人机交互方面取得了显著进展，使我们更接近AGI。然而，它们的部署需要大量的计算资源，这在数据、计算能力和模型优化方面带来了挑战。

### 边缘云计算和LLMs的动机
LLMs在数据可用性、计算能力、训练时间和推理延迟方面面临限制。边缘云计算提供了通过在数据源附近进行数据收集、高效利用边缘资源、协作训练和实时推理来优化资源利用和增强智能应用性能的解决方案。

### 相关工作和我们的贡献
本综述提供了LLMs的特征、发展和生命周期的全面概述。它探讨了边缘云计算和LLMs之间的共生关系，讨论了它们在各种场景中的应用，并识别了研究挑战和未来方向。

## LLMs基础
### LLMs的特征
LLMs以其大量的参数、复杂的模型结构和对大量训练数据的需求为特征。这些模型能够捕捉数据中的复杂模式和关系，使它们能够在各种任务中表现良好。

### LLMs的技术概述
Transformer架构是大多数LLMs的基础，利用自注意力机制来衡量句子中不同单词的重要性。为了应对训练LLMs的计算需求，采用了混合精度训练、梯度累积和分布式训练等技术。

### LLMs的分类
LLMs可以根据参数规模、技术架构、模态支持和应用领域进行分类。它们从通用模型到特定行业的模型，支持跨文本、图像、代码和视频领域的任务。

### LLMs的生命周期
LLMs的生命周期包括标记化、嵌入、预训练、监督微调、人类反馈强化学习和模型部署进行推理。每个阶段都涉及特定的技术和优化，以确保高效的训练和推理。

## 边缘云计算基础
### 边缘云计算范式
边缘云计算可以分为端-边缘、边缘-边缘、边缘-云和端-边缘-云协作范式。每种范式都利用边缘和云资源的不同方面来优化性能和资源利用。

### 边缘AI硬件用于LLMs
各种AI硬件，包括GPU、TPU、ASIC和FPGA，用于支持边缘上的LLMs训练和推理。这些硬件解决方案增强了计算效率，并实现了实时处理。

### 在边缘云计算网络中提供LLMs服务
部署LLMs时需要优化模型结构，确保与边缘设备的兼容性，并利用容器化技术实现标准化部署。有效的编排工具如Kubernetes可以管理资源，确保模型的可用性和可靠性。

## 边缘云计算赋能LLMs
### 边缘数据管理为LLMs服务
边缘服务器可以高效地收集多模态数据，减少数据传输成本。数据预处理和安全措施确保数据的高质量和隐私保护。

| 数据管理方面 | 描述 |
| --- | --- |
| 多模态数据收集 | 边缘服务器收集多模态数据，减少数据传输成本 |
| 数据预处理 | 数据清洗、格式化和去噪，确保数据质量 |
| 数据安全 | 利用联邦学习等技术保护数据隐私 |

### 边缘云计算为LLMs提供计算能力
边缘云计算通过计算能力供应、调度和交易优化LLMs的训练和推理。计算能力池化、动态资源调整和智能资源分配技术提高了资源利用效率。

| 计算能力优化 | 描述 |
| --- | --- |
| 计算能力供应 | 利用边缘设备的闲置计算能力 |
| 动态资源调整 | 根据需求动态调整计算资源分配 |
| 智能资源分配 | 利用机器学习算法优化资源分配 |

### 边缘为LLMs训练服务
并行训练方法（数据并行、模型并行和流水线并行）加速了LLMs的训练。分布式协作和增量学习进一步提高了训练效率。

| 训练方法 | 描述 |
| --- | --- |
| 数据并行 | 分布式训练数据，加速模型训练 |
| 模型并行 | 分布式模型参数，提高训练效率 |
| 流水线并行 | 分布式训练过程，优化资源利用 |

### 边缘为LLMs推理服务
模型稀疏化、量化、知识蒸馏和混合专家等优化方法提高了LLMs在资源受限的边缘设备上的推理效率。

| 推理优化方法 | 描述 |
| --- | --- |
| 模型稀疏化 | 减少模型参数，提高推理速度 |
| 量化 | 降低模型精度，减少计算需求 |
| 知识蒸馏 | 从大型模型中提取知识，训练小型模型 |
| 混合专家 | 分布式模型推理，提高效率 |

## LLMs驱动边缘云计算
### LLMs用于边缘通信系统
LLMs可以增强边缘通信系统，实现语义通信、改善用户交互、分析网络数据和生成边缘场景。

| 应用场景 | 描述 |
| --- | --- |
| 语义通信 | 通过LLMs实现高效的信息编码和解码 |
| 用户交互 | 提供实时、个性化的用户交互体验 |
| 网络数据分析 | 分析网络数据，优化网络性能 |
| 边缘场景生成 | 生成虚拟场景，用于模拟和训练 |

### LLMs用于边缘决策
LLMs在边缘场景中用于决策，包括计算卸载、内容缓存、模型协调和代理决策。这些应用利用了LLMs的高级推理能力。

| 决策应用 | 描述 |
| --- | --- |
| 计算卸载 | 动态分配计算任务到边缘或云端 |
| 内容缓存 | 优化内容缓存策略，提高访问速度 |
| 模型协调 | 协调边缘设备上的模型，提高效率 |
| 代理决策 | 为代理系统提供决策支持 |

### LLMs用于边缘个性化服务
通过将领域特定的知识注入LLMs，可以提供个性化服务。LLMs与小型模型的协作可以有效地利用私有数据，提供定制化的用户体验。

| 个性化服务 | 描述 |
| --- | --- |
| 领域知识注入 | 将特定领域的知识整合到LLMs中 |
| 模型协作 | LLMs与小型模型协作，提供个性化服务 |
| 用户体验优化 | 提供实时、个性化的用户体验 |

## 边缘环境中的LLMs应用
### 自动驾驶
LLMs在自动驾驶中用于车辆控制、路线规划和场景理解，提高了驾驶安全性和效率。

| 应用场景 | 描述 |
| --- | --- |
| 车辆控制 | 提供实时车辆控制决策 |
| 路线规划 | 优化路线规划，提高效率 |
| 场景理解 | 理解驾驶场景，提供安全建议 |

### 智能医疗
LLMs在智能医疗中用于医学图像分析、疾病描述和诊断辅助，提高了医疗服务的质量和效率。

---





# 2. Mobile Edge Intelligence for Large Language Models: A Contemporary Survey
> 原文链接：<https://ieeexplore.ieee.org/document/10835069>  
> 作者：Guanqiao Qu; Qiyuan Chen; Wei Wei; Zheng Lin; Xianhao Chen; Kaibin Huang  
> 期刊：IEEE Communications Surveys & Tutorials  
> 标签：#大型语言模型 #基础模型 #移动边缘计算 #边缘智能 #6G #分割学习

---

## 摘要
> 设备端大型语言模型 (LLM)，指的是在边缘设备上运行的 LLM，由于与云模式相比更具成本效益、延迟效率更高且更能保护隐私，已引起广泛关注。然而，设备端 LLM 的性能本质上受限于边缘设备的资源限制。移动边缘智能 (MEI) 介于云端 AI 和设备端 AI 之间，通过在移动网络边缘提供 AI 能力，提供了一种可行的解决方案。本文对如何利用 MEI 实现 LLM 进行了一项当代综述。我们首先举例说明几个杀手级应用，以说明在网络边缘部署 LLM 的迫切需求。接下来，我们将介绍 LLM 和 MEI 的基础知识，并介绍资源高效的 LLM 技术。然后，我们将概述 LLM 的 MEI (MEI4LLM) 架构，概述其核心组件及其如何支持 LLM 的部署。随后，我们将深入探讨 MEI4LLM 的各个方面，广泛涵盖边缘 LLM 的缓存和交付、边缘 LLM 训练以及边缘 LLM 推理。最后，我们展望了未来的研究方向。我们希望本文能够启发该领域的研究人员利用移动边缘计算来促进 LLM 的部署，从而释放 LLM 在各种隐私和延迟敏感型应用中的潜力。

## 引言
### 背景
- **LLMs的进展**：LLMs在自然语言处理（NLP）和多模态任务中表现出色，但对资源的需求极高，限制了其在边缘设备上的部署。
- **云部署的局限性**：云部署存在数据隐私泄露、高带宽成本和长服务延迟等问题，尤其是在隐私敏感的应用中，如移动健康和自动驾驶。

### 动机
- **on-device LLMs的挑战**：on-device LLMs面临计算、内存和存储资源的限制，难以支持大规模的LLMs。
- **MEI的优势**：MEI通过在移动网络边缘提供AI能力，解决了资源限制问题，支持低延迟的AI推理和训练服务。

### 贡献
- **应用场景分析**：提出了推动LLMs在网络边缘部署的应用场景，包括移动健康、人形机器人、虚拟助手和自动驾驶。
- **技术综述**：提供了6G边缘网络中边缘LLM缓存、训练和推理的全面综述，特别关注资源高效的LLM部署。
- **未来方向**：确定了MEI和LLMs整合的关键未来研究方向，包括绿色边缘AI、安全边缘AI和质量感知边缘训练。

## 应用场景
- **移动健康**：LLMs在医疗咨询、诊断和治疗建议中的应用，需要低延迟和高隐私保护。
- **人形机器人**：LLMs为机器人提供人类级别的智能，支持复杂的任务执行，如家务协助和救援任务。
- **虚拟助手**：LLMs提升虚拟助手的交互能力，提供更自然和智能的对话体验。
- **自动驾驶**：LLMs支持自动驾驶车辆的决策和路径规划，需要极低的延迟和高可靠性。

## 预备知识
### 大型语言模型（LLMs）
- **架构**：基于Transformer架构，适用于多种语言和多模态任务。
- **特性**：强大的语言理解和生成能力，支持复杂的推理和上下文感知任务。
- **挑战**：对计算、存储和通信资源的需求极高，限制了其在边缘设备上的部署。

### 移动边缘智能（MEI）
- **定义**：在移动网络边缘提供AI能力，支持数据收集、处理和分析。
- **优势**：减少数据传输延迟，提高数据隐私保护，支持实时AI服务。
- **应用**：广泛应用于智能健康、自动驾驶和智能城市等领域。

## 资源高效的LLM技术
- **模型压缩**：通过量化和剪枝减少模型大小，降低计算和存储需求。
- **快速解码**：优化解码过程，减少推理延迟。
- **参数高效的微调**：通过LoRA和适配器等技术，减少微调时的参数更新量。
- **零阶优化**：通过前向传播估计梯度，减少训练时的计算和内存需求。

## MEI4LLM框架
- **AI原生架构**：支持模型分割和并行训练，优化通信和计算资源。
- **参数共享LLM缓存和交付**：利用参数共享性，减少缓存和交付成本。
- **分布式LLM训练和推理**：支持联邦学习和分裂学习，提高训练和推理效率。

## 未来研究方向
- **绿色边缘AI**：开发能源高效的LLM训练和推理技术，减少能源消耗。
- **安全边缘AI**：设计安全机制，保护用户隐私和数据安全。
- **质量感知边缘训练**：提高训练数据质量，优化训练过程，提升LLMs性能。

## 结论
本文为利用MEI支持LLMs提供了全面的综述，指出了未来研究的方向，旨在推动LLMs在移动边缘网络中的高效部署。通过资源高效的LLM技术、优化的MEI4LLM框架和未来研究方向的探讨，本文为研究人员和实践者提供了宝贵的参考。



# 3. Large Language Model (LLM) for Telecommunications: A Comprehensive Survey on Principles, Key Techniques, and Opportunities
> 原文链接：<https://ieeexplore.ieee.org/document/10685369>  
> 作者：Hao Zhou; Chengming Hu; Ye Yuan; Yufei Cui; Yili Jin; Can Chen   
> 期刊：IEEE Communications Surveys & Tutorials  
> 标签：#大型语言模型 #电信 #生成 #分类 #预测 #优化

---

## 摘要
> 大型语言模型 (LLM) 因其出色的理解和推理能力，近年来备受关注，并在许多领域取得了巨大进步。LLM 技术的进步也为电信领域诸多任务的自动化提供了广阔的应用前景。经过预训练和微调后，LLM 可以根据人类指令执行各种下游任务，为实现通用人工智能 (AGI) 赋能的 6G 奠定基础。鉴于 LLM 技术的巨大潜力，本文旨在全面概述基于 LLM 的电信网络。首先，我们介绍 LLM 的基础知识，包括模型架构、预训练、微调、推理与应用、模型评估以及电信部署。然后，我们将从生成、分类、优化和预测问题的角度介绍基于 LLM 的关键技术和电信应用。具体而言，基于 LLM 的生成应用包括电信领域知识、代码和网络配置生成。之后，基于 LLM 的分类应用则涵盖网络安全、文本、图像和流量分类问题。此外，我们还介绍了多种基于LLM的优化技术，例如用于强化学习的自动奖励函数设计和言语强化学习。此外，针对LLM辅助预测问题，我们讨论了电信行业的时间序列预测模型和多模态预测问题。最后，我们重点介绍了LLM支持的电信网络面临的挑战，并展望了其未来发展方向。


## 引言

随着5G网络的商业部署以及6G网络的探索研究，电信领域对网络管理的复杂性显著增加。机器学习（ML）成为解决这一复杂性的有前途的解决方案之一。近年来，LLM技术因其出色的自然语言处理能力而受到广泛关注。本文旨在提供一个关于LLM在电信网络中应用的全面概述，特别关注其在生成、分类、优化和预测问题中的应用。

## 相关综述

本文与现有研究的主要区别在于，它不仅涵盖了LLM的基础技术，还详细介绍了LLM在电信领域的多种应用。此外，本文还探讨了LLM在电信领域应用中的挑战和未来方向，为研究人员提供了一个全面的参考。

## LLM基础

### 模型架构

LLM的核心是基于Transformer架构，它利用注意力机制捕捉输入和输出之间的全局依赖关系。Transformer架构包括编码器和解码器两个主要部分。编码器负责提取输入序列的特征，而解码器则负责生成输出序列。此外，LLM架构还可以分为仅编码器架构、编码器-解码器架构和仅解码器架构。

### LLM预训练

预训练的目的是让模型能够预测句子中的下一个单词。预训练过程包括数据收集、预处理和模型训练。数据收集涉及从网页、文献和对话语料库中获取数据。预处理步骤包括质量过滤、去重、隐私擦除和分词。模型训练则涉及批量大小和学习率的调整，以及3D并行化技术的使用。

### LLM微调

微调是指对预训练的LLM进行参数更新，以适应特定领域的任务。微调策略包括指令微调和对齐微调。指令微调通过使用自然语言格式的实例来微调LLM，而对齐微调则确保LLM的输出符合人类价值观。

### LLM推理和利用

LLM可以通过提示工程直接生成所需的输出，无需额外训练。提示工程的关键技术包括上下文学习（ICL）、链式思考（CoT）提示、复杂任务规划和自反馈迭代细化。

### LLM评估

评估LLM性能的指标包括准确性、幻觉现象、效率和与人类价值观的一致性。准确性衡量LLM对自然语言查询的理解和处理能力；幻觉现象指LLM生成错误或与事实不一致的信息；效率涉及计算资源需求和响应速度；与人类价值观的一致性则评估LLM输出是否符合社会规范和用户期望。

### LLM在电信网络中的部署

LLM在电信网络中的部署策略包括云端部署、网络边缘部署、设备端部署、缓存式部署和协作部署。云端部署利用中央云的强大计算资源，但响应时间较长；网络边缘部署可以缩短响应时间，但计算和存储资源有限；设备端部署则可以实现快速响应和本地定制，但对计算和存储资源要求较高。

## LLM在电信领域的应用

### 生成问题

LLM在电信领域的生成应用包括电信领域知识生成、代码生成和网络配置生成。这些应用可以显著节省人力，提高工作效率。例如，LLM可以生成电信领域的知识总结、代码和网络配置文件，还可以通过自反馈机制不断优化输出。

### 分类问题

LLM在电信领域的分类应用包括网络攻击分类、文本分类、图像分类和流量分类。LLM可以处理多模态和异构数据，具有零样本分类能力，能够快速响应电信网络中的各种分类任务。

### 优化问题

LLM在电信领域的优化应用包括自动化奖励函数设计、语言强化学习、LLM辅助无导数优化、端到端凸优化和LLM辅助启发式算法设计。这些技术可以降低优化问题的复杂性，提高优化效率。

### 预测问题

LLM在电信领域的预测应用包括时间序列预测模型和多模态预测问题。LLM可以预训练一个通用的时间序列模型，然后通过微调适应不同的预测任务。此外，LLM还可以处理多模态数据，提高预测的准确性。

## 挑战与未来方向

### 挑战

LLM在电信领域的应用面临以下挑战：

1. **电信领域LLM训练**：获取足够的电信领域数据集是训练电信领域LLM的主要挑战之一。此外，电信领域涉及大量复杂概念，需要有效的训练策略。
2. **LLM在电信领域的实际部署**：LLM需要在不同的网络层级（如云端、网络边缘和用户设备）进行部署，但每种部署方式都有其优缺点，需要综合考虑。
3. **电信应用的提示工程**：设计有效的提示是利用LLM的关键，但电信领域的复杂性使得提示设计具有挑战性。

### 未来方向

未来的研究方向包括：

1. **多模态LLM**：多模态LLM可以处理多种模态的数据，如文本、图像、音频和视频，为电信领域的应用提供更全面的解决方案。
2. **LLM辅助规划**：开发更好的算法以提高LLM在复杂任务中的规划能力，这对于解决电信领域的多步任务至关重要。
3. **LLM辅助资源分配和网络优化**：LLM可以将人类语言集成到优化过程中，使网络管理更加直观和可解释。
4. **LLM增强的机器学习**：LLM可以增强传统机器学习算法，使其在电信领域更加高效和可解释。
5. **LLM的实际应用**：随着技术的进步，LLM在电信行业的实际应用将不断拓展，如在设备上运行LLM以提高用户隐私和减少延迟。
6. **模型压缩和快速推理**：为了适应网络边缘和移动应用，需要开发模型压缩和快速推理技术，以减少LLM的存储和计算负担。
7. **解决幻觉问题**：减少LLM生成错误或与事实不一致信息的问题，提高其输出的可靠性。
8. **检索增强型LLM**：通过检索外部知识库来增强LLM的输出，使其能够基于最新信息生成更准确和相关的响应。
9. **经济实惠的LLM**：降低LLM的训练和部署成本，使其在电信领域的应用更加经济可行。

## 结论

本文全面综述了LLM在电信领域的应用，涵盖了LLM的基础原理、关键技术和应用前景。LLM在电信领域的应用具有巨大的潜力，但也面临着数据集、成本和技术实现等方面的挑战。未来的研究将集中在提高LLM的性能、降低成本以及开发新的应用领域，以推动电信行业的智能化发展。




# 4. Large Language Model Based Multi-Objective Optimization for Integrated Sensing and Communications in UAV Networks
> 原文链接：<https://ieeexplore.ieee.org/document/10839306>  
> 作者：Haoyun Li; Ming Xiao; Kezhi Wang; Dong In Kim; Merouane Debbah      
> 期刊：IEEE Wireless Communications Letters   
> 标签：#综合传感与通信 #多目标优化 #大型语言模型。
---

## 摘要
> 本文研究了一种具有集成感知和通信 (ISAC) 系统的无人驾驶飞行器 (UAV) 网络，其中多架无人机同时使用雷达感知地面用户的位置并提供通信服务。为了找到系统中通信和感知 (C&S) 之间的平衡，我们制定了一个多目标优化问题 (MOP)，以最大化总网络效用和地面用户的定位克拉美-罗界 (CRB)，从而联合优化无人机的部署和功率控制。受到大型语言模型 (LLM) 在预测和推理方面的巨大潜力的启发，我们提出了一种基于 LLM 的分解多目标进化算法 (LEDMA) 来解决高度非凸的 MOP。我们首先采用基于分解的方案将 MOP 分解为一系列优化子问题。其次，我们将 LLM 作为黑盒搜索算子与专门针对 MOP 设计的快速工程集成到 MOEA 框架中，以同时解决优化子问题。数值结果表明，所提出的 LEDMA 可以在 C&S 之间找到明确的权衡，并且在获得的帕累托前沿和收敛性方面优于基线 MOEA。

LLM 通过其强大的语言理解和生成能力，能够快速生成高质量的候选解。虽然 LLM 本身并不直接解决优化问题，但它可以通过生成多样化的候选解，帮助算法更快地探索解空间，找到更优的 Pareto 前沿。这种方法结合了 LLM 的生成能力和进化算法的优化能力，显著提高了优化效率。

## 研究背景
- **未来移动网络愿景**：B5G（Beyond 5G）网络不仅提供通信服务，还支持高精度感知能力。  
- **集成感知与通信（ISAC）**：无人机（UAV）网络凭借其高空优势和灵活机动性，成为实现 ISAC 的理想平台。  
- **通信与感知的权衡**：通信和感知共享信号，存在不可避免的权衡。如何在无人机网络中找到通信与感知之间的最佳平衡是一个关键问题。

---

## 研究方法
- **多目标优化问题（MOP）**：  
  - **目标 1**：最大化网络总效用（通信性能）。  
  - **目标 2**：最小化地面用户定位的克拉美罗界（CRB，感知性能）。  
  - 通过联合优化无人机的部署和功率控制来实现这两个目标。
- **算法设计**：  
  - **分解方法**：将 MOP 分解为多个优化子问题。  
  - **大语言模型（LLM）集成**：将 LLM 作为黑箱搜索算子，通过特定设计的提示（prompt）引导 LLM 解决优化子问题。  
  - 提出 **LLM 启用的分解式多目标进化算法（LEDMA）**。

---

## 实验结果
- **性能指标**：  
  - **收敛速度**：通过 Hypervolume（HV）指标衡量算法的收敛速度和多样性。  
  - **Pareto 前沿**：比较不同算法生成的 Pareto 前沿分布，评估算法在找到通信与感知权衡方面的表现。
- **关键发现**：  
  - **收敛优势**：LEDMA 在收敛速度上优于 RVEA、NSGA-II 和 MOEAD 等基线算法，最终 HV 值达到 1.194，显著高于其他算法。  
  - **Pareto 前沿质量**：LEDMA 生成的 Pareto 前沿更清晰、更接近理想方向，且在关键权衡区域生成更平滑、更密集的点。

---

## 结论
- **算法性能**：LEDMA 在解决无人机网络中的 ISAC 多目标优化问题上表现出色，优于现有基线算法。  
- **LLM 潜力**：展示了 LLM 在无线通信优化问题中的巨大潜力，为未来研究提供了新方向。  
- **未来工作**：将研究扩展到移动用户场景，并探索网络拓扑可扩展性对算法有效性的影响。

---

## 方法细节
- **系统模型**：  
  - **无人机网络**：包含 K 架无人机和 M 个地面用户。  
  - **信号传输**：无人机通过 FDMA 向地面用户传输 ISAC 信号，同时进行雷达感知。  
  - **定位与通信**：基于雷达回波信号计算 CRB 评估定位性能；基于信噪比（SINR）计算通信速率。
- **优化问题公式化**：  
  - **目标函数**：  
    - F1：最大化网络总效用（通信）。  
    - F2：最小化定位 CRB（感知）。  
  - **约束条件**：包括无人机功率限制和位置限制。
- **算法流程**：  
  - **初始化**：生成初始种群和权重向量。  
  - **进化**：利用 LLM 生成新解，通过设计提示整合问题描述、上下文示例和任务指令。  
  - **更新**：更新参考点、邻域解和外部种群（EP）。

---

## 实验设置
- **场景**：2 km × 2 km 区域内随机分布的地面用户。  
- **参数**：  
  - 无人机飞行高度 H = 100 m。  
  - 带宽 B = 51.2 MHz。  
  - 最大/最小传输功率 pmax = 20 dBm / pmin = 0 dBm。  
- **基线算法**：RVEA、MOEAD、AGE-MOEA、NSGA-II、MODEA。

---

## 关键数值结果
- **HV 指标**：LEDMA 达到 1.194，优于其他算法（MOEAD 1.129、AGE-MOEA 1.166 等）。  
- **Pareto 前沿分布**：LEDMA 在关键权衡区域生成更密集的点，表明其在通信与感知权衡方面表现更好。  
- **无人机部署与功率控制**：优化结果显示无人机 1 靠近底部用户，无人机 2 靠近顶部用户；在不同 Pareto 点下，无人机 1 更侧重通信任务，无人机 2 更侧重感知任务。

| **部分**     | **内容**        | **详细解释**                                                                                                                      |
| ---------- | ------------- | ----------------------------------------------------------------------------------------------------------------------------- |
| **研究背景**   | 未来移动网络愿景      | B5G网络不仅要提供通信服务，还要支持高精度感知能力                                                                                                    |
|            | 集成感知与通信（ISAC） | 无人机（UAV）网络凭借其高空优势和灵活机动性，成为实现ISAC的理想平台                                                                                         |
|            | 通信与感知的权衡      | 通信和感知共享信号，存在不可避免的权衡。如何在无人机网络中找到通信与感知之间的最佳平衡是一个关键问题                                                                            |
| **研究方法**   | 多目标优化问题（MOP）  | 目标1：最大化网络总效用（通信性能）<br>目标2：最小化地面用户定位的克拉美罗界（CRB，感知性能）<br>通过联合优化无人机的部署和功率控制来实现这两个目标                                              |
|            | 算法设计          | 分解方法：将MOP分解为多个优化子问题<br>大语言模型（LLM）集成：将LLM作为黑箱搜索算子，通过特定设计的提示（prompt）引导LLM解决优化子问题<br>提出LLM启用的分解式多目标进化算法（LEDMA）                   |
| **实验结果**   | 性能指标          | 收敛速度：通过Hypervolume（HV）指标衡量算法的收敛速度和多样性<br>Pareto前沿：比较不同算法生成的Pareto前沿分布，评估算法在找到通信与感知权衡方面的表现                                     |
|            | 关键发现          | 收敛优势：LEDMA在收敛速度上优于RVEA、NSGA-II和MOEAD等基线算法，最终HV值达到1.194，显著高于其他算法<br>Pareto前沿质量：LEDMA生成的Pareto前沿更清晰、更接近理想方向，且在关键权衡区域生成更平滑、更密集的点 |
| **结论**     | 算法性能          | LEDMA在解决无人机网络中的ISAC多目标优化问题上表现出色，优于现有基线算法                                                                                      |
|            | LLM潜力         | 展示了LLM在无线通信优化问题中的巨大潜力，为未来研究提供了新方向                                                                                             |
|            | 未来工作          | 将研究扩展到移动用户场景，并探索网络拓扑可扩展性对算法有效性的影响                                                                                             |
| **方法细节**   | 系统模型          | 无人机网络：包含K架无人机和M个地面用户<br>信号传输：无人机通过FDMA向地面用户传输ISAC信号，同时进行雷达感知<br>定位与通信：基于雷达回波信号计算CRB评估定位性能；基于信噪比（SINR）计算通信速率                   |
|            | 优化问题公式化       | 目标函数：<br>F1：最大化网络总效用（通信）<br>F2：最小化定位CRB（感知）<br>约束条件：包括无人机功率限制和位置限制                                                            |
|            | 算法流程          | 初始化：生成初始种群和权重向量<br>进化：利用LLM生成新解，通过设计提示整合问题描述、上下文示例和任务指令<br>更新：更新参考点、邻域解和外部种群（EP）                                              |
| **实验设置**   | 场景            | 2km×2km区域内随机分布的地面用户                                                                                                           |
|            | 参数            | 无人机飞行高度H=100m<br>带宽B=51.2MHz<br>最大/最小传输功率pmax=20dBm/pmin=0dBm                                                                 |
|            | 基线算法          | RVEA、MOEAD、AGE-MOEA、NSGA-II、MODEA                                                                                             |
| **关键数值结果** | HV指标          | LEDMA达到1.194，优于其他算法（MOEAD 1.129、AGE-MOEA 1.166等）                                                                              |
|            | Pareto前沿分布    | LEDMA在关键权衡区域生成更密集的点，表明其在通信与感知权衡方面表现更好                                                                                         |
|            | 无人机部署与功率控制    | 优化结果显示无人机1靠近底部用户，无人机2靠近顶部用户；在不同Pareto点下，无人机1更侧重通信任务，无人机2更侧重感知任务                                                               |
